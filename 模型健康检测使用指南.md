# 模型健康检测使用指南

## 功能概述

模型健康检测器是 InkFlow AI v1.8.0 新增的功能,允许您手动测试各个 AI 模型的可用性和网络延迟,帮助您:

- ✅ 验证 API 密钥是否正确配置
- ✅ 检查各个模型是否可用
- ✅ 测量网络延迟,选择最快的模型
- ✅ 排查连接问题

## 如何访问

1. 登录 InkFlow AI 系统
2. 点击右上角的"管理员登录"或直接访问管理后台
3. 在管理后台中,切换到"模型配置"标签
4. 点击右上角的"测试模型健康"按钮

## 功能说明

### 单个模型测试

- 点击任意模型右侧的"测试"按钮
- 系统会发送一个简单的测试请求到该模型
- 测试结果会显示:
  - ✅ **健康状态**: 绿色勾号表示模型可用
  - ⏱️ **延迟时间**: 显示响应时间(毫秒)
  - 📊 **延迟等级**: 
    - 优秀 (< 1秒)
    - 良好 (1-3秒)
    - 一般 (3-5秒)
    - 较慢 (> 5秒)
  - 💬 **响应预览**: 显示模型返回的前100个字符

### 批量测试

- 点击右上角的"全部测试"按钮
- 系统会依次测试所有模型
- 顶部显示测试进度 (例如: 测试中 3/10)
- 测试间隔500ms,避免请求过快

### 模型分组

模型按提供商分组显示:

1. **Google Gemini 系列**
   - Gemini Flash Lite (高性价比)
   - Gemini 2.5 Flash (均衡)
   - Gemini 2.5 Pro (高级推理)
   - Gemini 3 Pro (最强推理)
   - Gemini 2.0 Flash 实验版 (最新功能)

2. **阿里千问系列**
   - Qwen Turbo (快速)
   - Qwen Plus (增强)
   - Qwen Max (顶级)

3. **字节豆包系列**
   - Doubao Lite 4K (轻量)
   - Doubao Pro 32K (专业)

## 常见问题

### Q: 为什么某个模型显示"API密钥无效"?

**A**: 这通常意味着:
- 您的 API 密钥未正确配置
- 检查 `.env` 文件中的 `GEMINI_API_KEY` 是否正确
- 对于千问和豆包模型,需要单独配置它们的 API 密钥(目前仅支持 Gemini)

### Q: 为什么千问和豆包模型显示"功能待实现"?

**A**: 当前版本(v1.8.0)主要支持 Google Gemini 系列模型的健康检测。千问和豆包模型的完整支持将在后续版本中添加。您仍然可以在模型配置中看到这些模型,但健康检测功能需要额外的 SDK 集成。

### Q: 延迟时间包括哪些部分?

**A**: 延迟时间包括:
- 网络往返时间
- 模型处理时间
- API 响应时间

因此延迟会受到网络状况、模型负载等多种因素影响。

### Q: 如何选择最适合的模型?

**A**: 建议根据以下因素选择:

1. **任务复杂度**:
   - 简单任务(润色、短文): Flash Lite
   - 一般任务(章节生成): 2.5 Flash
   - 复杂任务(大纲架构): 2.5 Pro 或 3 Pro

2. **速度要求**:
   - 查看延迟测试结果
   - 选择延迟较低的模型

3. **成本考虑**:
   - Lite 和 Flash 系列性价比更高
   - Pro 系列功能强大但消耗更多配额

## 技术细节

### 测试流程

1. 系统创建一个 AI 客户端实例
2. 发送测试提示词: "请用一句话介绍你自己。"
3. 限制输出为 50 tokens,温度设为 0.1
4. 记录开始和结束时间,计算延迟
5. 解析响应和错误信息

### 错误处理

系统会自动识别常见错误:
- `API key not valid` → "API密钥无效"
- `not found` → "模型不存在"
- `quota` → "配额已用尽"
- `timeout` → "请求超时"

## 最佳实践

1. **定期检测**: 在开始大量创作任务前,先运行健康检测
2. **对比选择**: 使用批量测试对比不同模型的延迟
3. **记录结果**: 记下延迟最低的模型,作为首选
4. **错误排查**: 遇到问题时,先运行健康检测确认模型状态

## 更新日志

### v1.8.0 (2025-12-03)
- ✨ 首次发布模型健康检测功能
- ✨ 支持 Google Gemini 系列模型测试
- ✨ 添加延迟等级评估
- ✨ 支持批量测试和进度显示

---

如有问题或建议,请联系 InkFlow Team。
